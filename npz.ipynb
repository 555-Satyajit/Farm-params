{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d8618c9-152a-4246-a10f-4844abf28f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATYAJIT\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved for subset 1:\n",
      "Available arrays: ['X_train', 'y_train', 'X_val', 'y_val']\n",
      "X_train shape: (200000, 17)\n",
      "y_train shape: (200000,)\n",
      "X_val shape: (50000, 17)\n",
      "y_val shape: (50000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATYAJIT\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved for subset 2:\n",
      "Available arrays: ['X_train', 'y_train', 'X_val', 'y_val']\n",
      "X_train shape: (200000, 17)\n",
      "y_train shape: (200000,)\n",
      "X_val shape: (50000, 17)\n",
      "y_val shape: (50000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATYAJIT\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved for subset 3:\n",
      "Available arrays: ['X_train', 'y_train', 'X_val', 'y_val']\n",
      "X_train shape: (200000, 17)\n",
      "y_train shape: (200000,)\n",
      "X_val shape: (50000, 17)\n",
      "y_val shape: (50000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATYAJIT\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved for subset 4:\n",
      "Available arrays: ['X_train', 'y_train', 'X_val', 'y_val']\n",
      "X_train shape: (200000, 17)\n",
      "y_train shape: (200000,)\n",
      "X_val shape: (50000, 17)\n",
      "y_val shape: (50000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Read your CSV files\n",
    "df1 = pd.read_csv('subset_1.csv')\n",
    "df2 = pd.read_csv('subset_2.csv')\n",
    "df3 = pd.read_csv('subset_3.csv')\n",
    "df4 = pd.read_csv('subset_4.csv')\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = ['Soil_Type', 'Crop', 'Weather_Condition']\n",
    "numerical_features = ['Rainfall_mm', 'Temperature_Celsius', 'Fertilizer_Used',\n",
    "                     'Irrigation_Used', 'Days_to_Harvest']\n",
    "\n",
    "# Create preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Process each subset\n",
    "for idx, df in enumerate([df1, df2, df3, df4], start=1):\n",
    "    # Preprocess features\n",
    "    X = preprocessor.fit_transform(df[categorical_features + numerical_features])\n",
    "    y = df[target_column].values\n",
    "    \n",
    "    # Split into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Save with the expected keys\n",
    "    np.savez(\n",
    "        f'subset_{idx}_data.npz',\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val\n",
    "    )\n",
    "    \n",
    "    # Verify the saved data\n",
    "    loaded_data = np.load(f'subset_{idx}_data.npz')\n",
    "    print(f\"\\nData saved for subset {idx}:\")\n",
    "    print(f\"Available arrays:\", loaded_data.files)\n",
    "    print(f\"X_train shape:\", loaded_data['X_train'].shape)\n",
    "    print(f\"y_train shape:\", loaded_data['y_train'].shape)\n",
    "    print(f\"X_val shape:\", loaded_data['X_val'].shape)\n",
    "    print(f\"y_val shape:\", loaded_data['y_val'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b3247-04b4-461f-9ee9-c773334f947c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
