{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecf936d-7aa5-4a55-b9bb-d5662ce1ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335bab40-52ae-4a5b-84a9-d190d6bb8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('crop_yield.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cfec7d-cdd3-46fe-8960-aa9fac574a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Soil_Type</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Rainfall_mm</th>\n",
       "      <th>Temperature_Celsius</th>\n",
       "      <th>Fertilizer_Used</th>\n",
       "      <th>Irrigation_Used</th>\n",
       "      <th>Weather_Condition</th>\n",
       "      <th>Days_to_Harvest</th>\n",
       "      <th>Yield_tons_per_hectare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>897.077239</td>\n",
       "      <td>27.676966</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>122</td>\n",
       "      <td>6.555816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South</td>\n",
       "      <td>Clay</td>\n",
       "      <td>Rice</td>\n",
       "      <td>992.673282</td>\n",
       "      <td>18.026142</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>140</td>\n",
       "      <td>8.527341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North</td>\n",
       "      <td>Loam</td>\n",
       "      <td>Barley</td>\n",
       "      <td>147.998025</td>\n",
       "      <td>29.794042</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>106</td>\n",
       "      <td>1.127443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Soybean</td>\n",
       "      <td>986.866331</td>\n",
       "      <td>16.644190</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>146</td>\n",
       "      <td>6.517573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South</td>\n",
       "      <td>Silt</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>730.379174</td>\n",
       "      <td>31.620687</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>110</td>\n",
       "      <td>7.248251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region Soil_Type     Crop  Rainfall_mm  Temperature_Celsius  \\\n",
       "0   West     Sandy   Cotton   897.077239            27.676966   \n",
       "1  South      Clay     Rice   992.673282            18.026142   \n",
       "2  North      Loam   Barley   147.998025            29.794042   \n",
       "3  North     Sandy  Soybean   986.866331            16.644190   \n",
       "4  South      Silt    Wheat   730.379174            31.620687   \n",
       "\n",
       "   Fertilizer_Used  Irrigation_Used Weather_Condition  Days_to_Harvest  \\\n",
       "0            False             True            Cloudy              122   \n",
       "1             True             True             Rainy              140   \n",
       "2            False            False             Sunny              106   \n",
       "3            False             True             Rainy              146   \n",
       "4             True             True            Cloudy              110   \n",
       "\n",
       "   Yield_tons_per_hectare  \n",
       "0                6.555816  \n",
       "1                8.527341  \n",
       "2                1.127443  \n",
       "3                6.517573  \n",
       "4                7.248251  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62c4452b-4f4c-4909-8fc0-e764d874e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91d2ac9c-7347-4f99-80d6-bd523c373a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [df1[i:i + 2500000] for i in range(0, len(df1), 2500000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "556bee4e-d310-4e0b-8757-0a704a2435ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, subset in enumerate(subsets):\n",
    "    subset.to_csv(f'subset_{i+1}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "518d9b06-d2c7-4d69-9e11-407938cd4360",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'subset_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m client_1_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubset_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m client_2_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubset_2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m client_3_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubset_3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m client_4_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubset_4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'subset_2.csv'"
     ]
    }
   ],
   "source": [
    "client_1_data = pd.read_csv('subset_1.csv')\n",
    "client_2_data = pd.read_csv('subset_2.csv')\n",
    "client_3_data = pd.read_csv('subset_3.csv')\n",
    "client_4_data = pd.read_csv('subset_4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bf1d207-c98c-445e-82d5-780e063d6098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_1.csv: Exists\n",
      "subset_2.csv: Missing\n",
      "subset_3.csv: Missing\n",
      "subset_4.csv: Missing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check for subset files\n",
    "for i in range(1, 5):\n",
    "    file_name = f'subset_{i}.csv'\n",
    "    print(f\"{file_name}: {'Exists' if os.path.exists(file_name) else 'Missing'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14b399ce-8e66-41d1-9eff-6917a551ac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: subset_1.csv (Rows: 250000)\n",
      "Saved: subset_2.csv (Rows: 250000)\n",
      "Saved: subset_3.csv (Rows: 250000)\n",
      "Saved: subset_4.csv (Rows: 250000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('crop_yield.csv')\n",
    "\n",
    "# Number of rows per subset\n",
    "total_rows = len(data)\n",
    "rows_per_subset = total_rows // 4\n",
    "\n",
    "# Split the dataset into 4 subsets\n",
    "subsets = [\n",
    "    data.iloc[i * rows_per_subset: (i + 1) * rows_per_subset]\n",
    "    for i in range(4)\n",
    "]\n",
    "\n",
    "# Handle remaining rows for the last subset\n",
    "subsets[-1] = data.iloc[3 * rows_per_subset:]\n",
    "\n",
    "# Save each subset\n",
    "for i, subset in enumerate(subsets):\n",
    "    file_name = f'subset_{i+1}.csv'\n",
    "    subset.to_csv(file_name, index=False)\n",
    "    print(f\"Saved: {file_name} (Rows: {len(subset)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf07860-407c-4413-b90b-91b28b085dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sandy', 'Clay', 'Loam', 'Silt', 'Peaty', 'Chalky'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Soil_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861ee30a-79a2-4301-abc2-77cb7d4d63a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cotton', 'Rice', 'Barley', 'Soybean', 'Wheat', 'Maize'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crop'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e48b2f0-060a-421b-94c6-3aecce029eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cloudy', 'Rainy', 'Sunny'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weather_Condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324aaf4-9545-4282-8554-da1d98cc6b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
