{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cec91ed-290d-428e-bdc8-401a3708d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists, skipping clone.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import git\n",
    "\n",
    "# Define the repository URL and the local directory to clone into\n",
    "repo_url = \"https://github.com/555-Satyajit/Farm-params.git\"\n",
    "local_dir = r\"C:\\Users\\SATYAJIT\\crop yield\\Farm-Params\"  # The directory where the repo will be cloned\n",
    "\n",
    "# Clone the repository if it does not already exist\n",
    "if not os.path.exists(local_dir):\n",
    "    try:\n",
    "        print(\"Cloning the repository...\")\n",
    "        git.Repo.clone_from(repo_url, local_dir)\n",
    "        print(\"Repository cloned successfully!\")\n",
    "    except git.exc.GitCommandError as e:\n",
    "        print(f\"Error during cloning: {e}\")\n",
    "else:\n",
    "    print(\"Repository already exists, skipping clone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4645cfc0-e3e5-428b-881f-f29076e02ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters for Client 1 saved to MongoDB!\n",
      "Model parameters for Client 2 saved to MongoDB!\n",
      "Model parameters for Client 3 saved to MongoDB!\n",
      "Model parameters for Client 4 saved to MongoDB!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel parameters for Client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved to MongoDB!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Wait for any ongoing processes to release the folder before deletion\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Try to delete the repository folder after processing\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Path to the cloned repository\n",
    "repo_path = \"Farm-params\"  # Adjust if your repo path is different\n",
    "\n",
    "# Initialize MongoDB client\n",
    "client = MongoClient('mongodb://localhost:27017/')  # Adjust if necessary\n",
    "db = client['fed_avg']  # Name of the database\n",
    "collection = db['model_params']  # Collection for storing model parameters\n",
    "\n",
    "# Loop over client numbers (1 to 4) to load parameters and store them in MongoDB\n",
    "for client_num in range(1, 5):\n",
    "    # Load the coefficients and intercepts for each client\n",
    "    coef = np.load(os.path.join(repo_path, f'coef_client_{client_num}.npy'))\n",
    "    intercept = np.load(os.path.join(repo_path, f'intercept_client_{client_num}.npy'))\n",
    "    \n",
    "    # Convert numpy arrays to lists for MongoDB compatibility\n",
    "    params = {\n",
    "        'coef': coef.tolist(),\n",
    "        'intercept': intercept.tolist()\n",
    "    }\n",
    "    \n",
    "    # Insert the data into MongoDB\n",
    "    collection.insert_one({f\"client_{client_num}_params\": params})\n",
    "    \n",
    "    print(f\"Model parameters for Client {client_num} saved to MongoDB!\")\n",
    "\n",
    "# Wait for any ongoing processes to release the folder before deletion\n",
    "time.sleep(2)\n",
    "\n",
    "# Try to delete the repository folder after processing\n",
    "try:\n",
    "    shutil.rmtree(repo_path)\n",
    "    print(f\"Successfully deleted the repository at {repo_path}.\")\n",
    "except PermissionError as e:\n",
    "    print(f\"PermissionError: {e}. Try closing any processes that may be using the folder.\")\n",
    "    # Optionally, you could try deleting the folder manually if needed.\n",
    "except Exception as e:\n",
    "    print(f\"Error during deletion: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a97e868-a386-42ce-bdd3-e52d849adf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists, skipping clone.\n",
      "\n",
      "Federated Learning Round 1\n",
      "Selected clients: [4, 1, 3]\n",
      "Client 4 completed local training\n",
      "Client 1 completed local training\n",
      "Client 3 completed local training\n",
      "Round 1 aggregation completed\n",
      "\n",
      "Federated Learning Round 2\n",
      "Selected clients: [3, 2, 4]\n",
      "Client 3 completed local training\n",
      "Client 2 completed local training\n",
      "Client 4 completed local training\n",
      "Round 2 aggregation completed\n",
      "\n",
      "Federated Learning Round 3\n",
      "Selected clients: [1, 2, 3]\n",
      "Client 1 completed local training\n",
      "Client 2 completed local training\n",
      "Client 3 completed local training\n",
      "Round 3 aggregation completed\n",
      "\n",
      "Federated Learning Round 4\n",
      "Selected clients: [1, 3, 4]\n",
      "Client 1 completed local training\n",
      "Client 3 completed local training\n",
      "Client 4 completed local training\n",
      "Round 4 aggregation completed\n",
      "\n",
      "Federated Learning Round 5\n",
      "Selected clients: [1, 2, 4]\n",
      "Client 1 completed local training\n",
      "Client 2 completed local training\n",
      "Client 4 completed local training\n",
      "Round 5 aggregation completed\n",
      "\n",
      "Final global model saved as globalmodel1.pkl!\n",
      "Error during cleanup: [WinError 5] Access is denied: 'Farm-params\\\\.git\\\\objects\\\\pack\\\\pack-9793a28fd66f88728bbd621fe2ee08d7dd711de3.idx'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import random\n",
    "\n",
    "class FederatedServer:\n",
    "    def __init__(self, num_rounds: int = 5, client_fraction: float = 0.8):\n",
    "        self.global_model = None\n",
    "        self.num_rounds = num_rounds\n",
    "        self.client_fraction = client_fraction\n",
    "        self.clients = []\n",
    "        \n",
    "    def initialize_global_model(self):\n",
    "        \"\"\"Initialize global model parameters\"\"\"\n",
    "        self.global_model = {\n",
    "            'coefficients': None,\n",
    "            'intercept': None\n",
    "        }\n",
    "    \n",
    "    def select_clients(self) -> List[int]:\n",
    "        \"\"\"Randomly select a fraction of clients for each round\"\"\"\n",
    "        num_clients = len(self.clients)\n",
    "        num_selected = max(1, int(self.client_fraction * num_clients))\n",
    "        return random.sample(range(num_clients), num_selected)\n",
    "    \n",
    "    def aggregate_models(self, client_models: List[Dict]) -> Dict:\n",
    "        \"\"\"Aggregate client models using FedAvg\"\"\"\n",
    "        coef_array = []\n",
    "        intercept_array = []\n",
    "        \n",
    "        # Get the maximum coefficient size\n",
    "        max_coef_size = max(coef.shape[0] for coef in \n",
    "                          [model['coefficients'] for model in client_models])\n",
    "        \n",
    "        for model in client_models:\n",
    "            coef = model['coefficients']\n",
    "            # Pad smaller arrays with zeros\n",
    "            if coef.shape[0] < max_coef_size:\n",
    "                coef = np.pad(coef, (0, max_coef_size - coef.shape[0]), \n",
    "                            mode='constant', constant_values=0)\n",
    "            coef_array.append(coef)\n",
    "            intercept_array.append(model['intercept'])\n",
    "        \n",
    "        return {\n",
    "            'coefficients': np.mean(coef_array, axis=0),\n",
    "            'intercept': np.mean(intercept_array, axis=0)\n",
    "        }\n",
    "\n",
    "class FederatedClient:\n",
    "    def __init__(self, client_id: int, data_path: str):\n",
    "        self.client_id = client_id\n",
    "        self.data_path = data_path\n",
    "        self.model = LinearRegression()\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load client's local data\"\"\"\n",
    "        # In your case, loading pre-trained coefficients and intercepts\n",
    "        self.coef = np.load(os.path.join(self.data_path, f'coef_client_{self.client_id}.npy'))\n",
    "        self.intercept = np.load(os.path.join(self.data_path, \n",
    "                                            f'intercept_client_{self.client_id}.npy'))\n",
    "    \n",
    "    def train_local_model(self, global_model=None):\n",
    "        \"\"\"Train local model using client's data\"\"\"\n",
    "        if global_model is not None and global_model['coefficients'] is not None:\n",
    "            # Initialize local model with global parameters\n",
    "            self.coef = global_model['coefficients']\n",
    "            self.intercept = global_model['intercept']\n",
    "        \n",
    "        # In a real implementation, you would train the model here\n",
    "        # For now, we're just using the pre-trained parameters\n",
    "        \n",
    "        return {\n",
    "            'coefficients': self.coef,\n",
    "            'intercept': self.intercept\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Define paths\n",
    "    repo_url = \"https://github.com/555-Satyajit/Farm-params.git\"\n",
    "    local_dir = r\"C:\\Users\\SATYAJIT\\crop yield\\Farm-Params\"\n",
    "    repo_path = \"Farm-params\"\n",
    "\n",
    "    # Clone repository\n",
    "    if not os.path.exists(local_dir):\n",
    "        try:\n",
    "            print(\"Cloning the repository...\")\n",
    "            git.Repo.clone_from(repo_url, local_dir)\n",
    "            print(\"Repository cloned successfully!\")\n",
    "        except git.exc.GitCommandError as e:\n",
    "            print(f\"Error during cloning: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Repository already exists, skipping clone.\")\n",
    "\n",
    "    # Initialize server\n",
    "    server = FederatedServer(num_rounds=5, client_fraction=0.8)\n",
    "    server.initialize_global_model()\n",
    "\n",
    "    # Initialize clients\n",
    "    for client_id in range(1, 5):\n",
    "        client = FederatedClient(client_id, repo_path)\n",
    "        try:\n",
    "            client.load_data()\n",
    "            server.clients.append(client)\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing client {client_id}: {e}\")\n",
    "\n",
    "    # Federated Learning rounds\n",
    "    for round_num in range(server.num_rounds):\n",
    "        print(f\"\\nFederated Learning Round {round_num + 1}\")\n",
    "        \n",
    "        # Select clients for this round\n",
    "        selected_clients = server.select_clients()\n",
    "        print(f\"Selected clients: {[i+1 for i in selected_clients]}\")\n",
    "        \n",
    "        # Collect client updates\n",
    "        client_models = []\n",
    "        for client_idx in selected_clients:\n",
    "            client = server.clients[client_idx]\n",
    "            # Train local model (in this case, just using pre-trained parameters)\n",
    "            client_model = client.train_local_model(server.global_model)\n",
    "            client_models.append(client_model)\n",
    "            print(f\"Client {client.client_id} completed local training\")\n",
    "        \n",
    "        # Aggregate models\n",
    "        server.global_model = server.aggregate_models(client_models)\n",
    "        print(f\"Round {round_num + 1} aggregation completed\")\n",
    "\n",
    "    # Save final global model\n",
    "    try:\n",
    "        with open('globalmodel1.pkl', 'wb') as f:\n",
    "            pickle.dump(server.global_model, f)\n",
    "        print(\"\\nFinal global model saved as globalmodel1.pkl!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving global model: {e}\")\n",
    "\n",
    "    # Cleanup\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        shutil.rmtree(repo_path)\n",
    "        print(f\"Successfully deleted the repository at {repo_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51837539-befc-4c5b-a715-91e57e6c504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Analyzing data structure...\n",
      "\n",
      "Data Analysis:\n",
      "\n",
      "Region unique values:\n",
      "['West' 'South' 'North' 'East']\n",
      "\n",
      "Soil_Type unique values:\n",
      "['Sandy' 'Clay' 'Loam' 'Silt' 'Peaty' 'Chalky']\n",
      "\n",
      "Crop unique values:\n",
      "['Cotton' 'Rice' 'Barley' 'Soybean' 'Wheat' 'Maize']\n",
      "\n",
      "Weather_Condition unique values:\n",
      "['Cloudy' 'Rainy' 'Sunny']\n",
      "\n",
      "Numeric columns statistics:\n",
      "          Rainfall_mm  Temperature_Celsius  Days_to_Harvest  \\\n",
      "count  1000000.000000       1000000.000000   1000000.000000   \n",
      "mean       549.981901            27.504965       104.495025   \n",
      "std        259.851320             7.220608        25.953412   \n",
      "min        100.000896            15.000034        60.000000   \n",
      "25%        324.891090            21.254502        82.000000   \n",
      "50%        550.124061            27.507365       104.000000   \n",
      "75%        774.738520            33.753267       127.000000   \n",
      "max        999.998098            39.999997       149.000000   \n",
      "\n",
      "       Yield_tons_per_hectare  \n",
      "count          1000000.000000  \n",
      "mean                 4.649472  \n",
      "std                  1.696572  \n",
      "min                 -1.147613  \n",
      "25%                  3.417637  \n",
      "50%                  4.651808  \n",
      "75%                  5.879200  \n",
      "max                  9.963372  \n",
      "\n",
      "Performing feature engineering...\n",
      "\n",
      "Features after engineering:\n",
      "Number of features: 20\n",
      "Feature names: ['Region', 'Soil_Type', 'Crop', 'Rainfall_mm', 'Temperature_Celsius', 'Fertilizer_Used', 'Irrigation_Used', 'Weather_Condition', 'Days_to_Harvest', 'Rainfall_Temp_Interaction', 'Growing_Conditions', 'Water_Availability', 'Growth_Index', 'Rainfall_mm_Squared', 'Temperature_Celsius_Squared', 'Days_to_Harvest_Squared', 'Region_Rainfall', 'Soil_Temperature', 'High_Rainfall', 'High_Temperature']\n",
      "\n",
      "Splitting data into train and test sets...\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Input shape: (200000, 20)\n",
      "Coefficient shape: (17,)\n",
      "Using first 17 features. New input shape: (200000, 17)\n",
      "\n",
      "Model Evaluation Metrics:\n",
      "R² Score: -7.4194\n",
      "MSE: 24.2726\n",
      "RMSE: 4.9267\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_data(df):\n",
    "    \"\"\"\n",
    "    Analyze the dataset to understand the available values\n",
    "    \"\"\"\n",
    "    print(\"\\nData Analysis:\")\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            print(f\"\\n{column} unique values:\")\n",
    "            print(df[column].unique())\n",
    "    \n",
    "    print(\"\\nNumeric columns statistics:\")\n",
    "    print(df.describe())\n",
    "    return df.select_dtypes(include=['object']).columns\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Transform original features into expanded feature set\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original data\n",
    "    X = df.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_dict = {}\n",
    "    categorical_cols = ['Region', 'Soil_Type', 'Crop', 'Weather_Condition']\n",
    "    for col in categorical_cols:\n",
    "        le_dict[col] = LabelEncoder()\n",
    "        X[col] = le_dict[col].fit_transform(X[col])\n",
    "    \n",
    "    # Create interaction features\n",
    "    X['Rainfall_Temp_Interaction'] = X['Rainfall_mm'] * X['Temperature_Celsius']\n",
    "    X['Growing_Conditions'] = X['Rainfall_mm'] / (X['Temperature_Celsius'] + 1)\n",
    "    \n",
    "    # Create agricultural specific features\n",
    "    X['Water_Availability'] = X['Rainfall_mm'] + (X['Irrigation_Used'] * 500)\n",
    "    X['Growth_Index'] = (X['Temperature_Celsius'] * X['Rainfall_mm'] * X['Fertilizer_Used']) / 1000\n",
    "    \n",
    "    # Create squared terms for numerical features\n",
    "    numeric_features = ['Rainfall_mm', 'Temperature_Celsius', 'Days_to_Harvest']\n",
    "    for feature in numeric_features:\n",
    "        X[f'{feature}_Squared'] = X[feature] ** 2\n",
    "    \n",
    "    # Interaction between categorical and numerical features\n",
    "    X['Region_Rainfall'] = X['Region'] * X['Rainfall_mm']\n",
    "    X['Soil_Temperature'] = X['Soil_Type'] * X['Temperature_Celsius']\n",
    "    \n",
    "    # Binary features\n",
    "    X['High_Rainfall'] = (X['Rainfall_mm'] > X['Rainfall_mm'].mean()).astype(int)\n",
    "    X['High_Temperature'] = (X['Temperature_Celsius'] > X['Temperature_Celsius'].mean()).astype(int)\n",
    "    \n",
    "    # Normalize numeric features\n",
    "    numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "    \n",
    "    print(\"\\nFeatures after engineering:\")\n",
    "    print(f\"Number of features: {X.shape[1]}\")\n",
    "    print(\"Feature names:\", list(X.columns))\n",
    "    \n",
    "    return X\n",
    "\n",
    "def evaluate_global_model(model_path, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the global model using various metrics\n",
    "    \"\"\"\n",
    "    # Load the global model\n",
    "    with open(model_path, 'rb') as f:\n",
    "        global_model = pickle.load(f)\n",
    "    \n",
    "    print(f\"\\nInput shape: {X_test.shape}\")\n",
    "    print(f\"Coefficient shape: {global_model['coefficients'].shape}\")\n",
    "    \n",
    "    # Select only the first 17 features if we have more\n",
    "    if X_test.shape[1] > 17:\n",
    "        X_test = X_test.iloc[:, :17]\n",
    "        print(f\"Using first 17 features. New input shape: {X_test.shape}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = np.dot(X_test, global_model['coefficients']) + global_model['intercept']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nModel Evaluation Metrics:\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_evaluation_plots(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'r2_score': r2,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'predictions': y_pred,\n",
    "        'errors': y_test - y_pred\n",
    "    }\n",
    "\n",
    "def create_evaluation_plots(y_test, y_pred):\n",
    "    \"\"\"Create and save evaluation plots\"\"\"\n",
    "    # Scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Yield (tons/hectare)')\n",
    "    plt.ylabel('Predicted Yield (tons/hectare)')\n",
    "    plt.title('Actual vs Predicted Crop Yield')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('yield_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=30, edgecolor='black')\n",
    "    plt.xlabel('Prediction Error (tons/hectare)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Prediction Errors')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('yield_errors.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # File paths\n",
    "    data_path = \"crop_yield.csv\"\n",
    "    model_path = \"globalmodel1.pkl\"\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Analyze data first\n",
    "        print(\"\\nAnalyzing data structure...\")\n",
    "        categorical_columns = analyze_data(df)\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = df.drop(['Yield_tons_per_hectare'], axis=1)\n",
    "        y = df['Yield_tons_per_hectare']\n",
    "        \n",
    "        # Perform feature engineering\n",
    "        print(\"\\nPerforming feature engineering...\")\n",
    "        X_engineered = engineer_features(X)\n",
    "        \n",
    "        # Split the data\n",
    "        print(\"\\nSplitting data into train and test sets...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_engineered, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"\\nEvaluating model...\")\n",
    "        results = evaluate_global_model(model_path, X_test, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"\\nFull error traceback:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7706610-f79e-4c72-a838-996339e502c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists, skipping clone.\n",
      "Client 1 feature dimension: 17\n",
      "Client 2 feature dimension: 17\n",
      "Client 3 feature dimension: 8\n",
      "Client 4 feature dimension: 8\n",
      "Maximum feature dimension across clients: 17\n",
      "\n",
      "Federated Learning Round 1\n",
      "Selected clients: [3, 2, 1, 4]\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Error during model aggregation in round 1: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 2\n",
      "Selected clients: [4, 1, 3, 2]\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Error during model aggregation in round 2: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 3\n",
      "Selected clients: [2, 3, 4, 1]\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Error during model aggregation in round 3: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 4\n",
      "Selected clients: [3, 2, 4, 1]\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Error during model aggregation in round 4: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 5\n",
      "Selected clients: [3, 2, 1, 4]\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Error during model aggregation in round 5: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 6\n",
      "Selected clients: [4, 1, 3, 2]\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Error during model aggregation in round 6: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 7\n",
      "Selected clients: [1, 2, 3, 4]\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Error during model aggregation in round 7: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 8\n",
      "Selected clients: [1, 2, 3, 4]\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Error during model aggregation in round 8: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 9\n",
      "Selected clients: [3, 1, 2, 4]\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Error during model aggregation in round 9: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Federated Learning Round 10\n",
      "Selected clients: [2, 4, 1, 3]\n",
      "Client 2 completed local training (R² score: 0.996)\n",
      "Client 4 completed local training (R² score: 0.990)\n",
      "Client 1 completed local training (R² score: 0.995)\n",
      "Client 3 completed local training (R² score: 0.988)\n",
      "Error during model aggregation in round 10: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.\n",
      "\n",
      "Final global model saved as globalmodel1.pkl! Best R² score: -inf\n",
      "Error during cleanup: [WinError 5] Access is denied: 'Farm-params\\\\.git\\\\objects\\\\pack\\\\pack-9793a28fd66f88728bbd621fe2ee08d7dd711de3.idx'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "\n",
    "class FederatedServer:\n",
    "    def __init__(self, num_rounds: int = 10, client_fraction: float = 1.0, learning_rate: float = 0.1):\n",
    "        self.global_model = None\n",
    "        self.num_rounds = num_rounds\n",
    "        self.client_fraction = client_fraction\n",
    "        self.clients = []\n",
    "        self.feature_dim = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.best_model = None\n",
    "        self.best_score = float('-inf')\n",
    "        \n",
    "    def initialize_global_model(self, feature_dim: int):\n",
    "        \"\"\"Initialize global model parameters with random values\"\"\"\n",
    "        self.feature_dim = feature_dim\n",
    "        self.global_model = {\n",
    "            'coefficients': np.random.randn(feature_dim) * 0.01,  # Small random initialization\n",
    "            'intercept': 0.0\n",
    "        }\n",
    "        self.best_model = self.global_model.copy()\n",
    "    \n",
    "    def select_clients(self) -> List[int]:\n",
    "        \"\"\"Randomly select a fraction of clients for each round\"\"\"\n",
    "        num_clients = len(self.clients)\n",
    "        num_selected = max(1, int(self.client_fraction * num_clients))\n",
    "        return random.sample(range(num_clients), num_selected)\n",
    "    \n",
    "    def aggregate_models(self, client_models: List[Dict], client_weights: List[float], \n",
    "                        client_scores: List[float]) -> Dict:\n",
    "        \"\"\"Aggregate client models using weighted FedAvg with performance-based weighting\"\"\"\n",
    "        if not client_models:\n",
    "            return self.global_model\n",
    "            \n",
    "        # Convert negative R² scores to small positive weights\n",
    "        scores = np.array(client_scores)\n",
    "        scores = np.exp(scores) / np.sum(np.exp(scores))  # Softmax normalization\n",
    "        \n",
    "        # Combine performance scores with data size weights\n",
    "        weights = np.array(client_weights) * scores\n",
    "        weights = weights / np.sum(weights)\n",
    "        \n",
    "        # Weighted average with momentum\n",
    "        momentum = 0.9\n",
    "        weighted_coef = np.average(\n",
    "            [model['coefficients'] for model in client_models],\n",
    "            weights=weights,\n",
    "            axis=0\n",
    "        )\n",
    "        weighted_intercept = np.average(\n",
    "            [model['intercept'] for model in client_models],\n",
    "            weights=weights\n",
    "        )\n",
    "        \n",
    "        # Apply momentum update\n",
    "        new_model = {\n",
    "            'coefficients': momentum * self.global_model['coefficients'] + \n",
    "                          (1 - momentum) * weighted_coef,\n",
    "            'intercept': momentum * self.global_model['intercept'] + \n",
    "                        (1 - momentum) * weighted_intercept\n",
    "        }\n",
    "        \n",
    "        return new_model\n",
    "\n",
    "class FederatedClient:\n",
    "    def __init__(self, client_id: int, data_path: str, expected_dim: int = None):\n",
    "        self.client_id = client_id\n",
    "        self.data_path = data_path\n",
    "        self.model = LinearRegression()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.expected_dim = expected_dim\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        \n",
    "    def load_data(self) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"Load and preprocess client's local data\"\"\"\n",
    "        try:\n",
    "            coef = np.load(os.path.join(self.data_path, f'coef_client_{self.client_id}.npy'))\n",
    "            intercept = np.load(os.path.join(self.data_path, \n",
    "                                           f'intercept_client_{self.client_id}.npy'))\n",
    "            \n",
    "            # Generate synthetic data based on coefficients\n",
    "            num_samples = 1000  # Increase for more training data\n",
    "            X = np.random.randn(num_samples, len(coef))\n",
    "            y = np.dot(X, coef) + intercept + np.random.randn(num_samples) * 0.1\n",
    "            \n",
    "            # Split data into train and validation sets\n",
    "            self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "            self.X_val = self.scaler.transform(self.X_val)\n",
    "            \n",
    "            # Handle dimension mismatch\n",
    "            if self.expected_dim is not None:\n",
    "                if coef.shape[0] < self.expected_dim:\n",
    "                    coef = np.pad(coef, (0, self.expected_dim - coef.shape[0]))\n",
    "                elif coef.shape[0] > self.expected_dim:\n",
    "                    coef = coef[:self.expected_dim]\n",
    "                    \n",
    "            self.coef = coef\n",
    "            self.intercept = intercept\n",
    "            return len(self.X_train)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for client {self.client_id}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def train_local_model(self, global_model: Dict) -> Tuple[Dict, float]:\n",
    "        \"\"\"Train local model using client's data and evaluate performance\"\"\"\n",
    "        if global_model is not None:\n",
    "            # Initialize local model with global parameters\n",
    "            self.model.coef_ = global_model['coefficients'].copy()\n",
    "            self.model.intercept_ = global_model['intercept']\n",
    "            \n",
    "            # Fine-tune on local data\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_score = r2_score(self.y_val, self.model.predict(self.X_val))\n",
    "            \n",
    "            return {\n",
    "                'coefficients': self.model.coef_,\n",
    "                'intercept': self.model.intercept_\n",
    "            }, val_score\n",
    "        \n",
    "        return {\n",
    "            'coefficients': self.coef,\n",
    "            'intercept': self.intercept\n",
    "        }, 0.0\n",
    "\n",
    "def main():\n",
    "    repo_url = \"https://github.com/555-Satyajit/Farm-params.git\"\n",
    "    local_dir = r\"C:\\Users\\SATYAJIT\\crop yield\\Farm-Params\"\n",
    "    repo_path = \"Farm-params\"\n",
    "\n",
    "    # Clone repository\n",
    "    if not os.path.exists(local_dir):\n",
    "        try:\n",
    "            print(\"Cloning the repository...\")\n",
    "            git.Repo.clone_from(repo_url, local_dir)\n",
    "            print(\"Repository cloned successfully!\")\n",
    "        except git.exc.GitCommandError as e:\n",
    "            print(f\"Error during cloning: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Repository already exists, skipping clone.\")\n",
    "\n",
    "    # First pass: determine maximum feature dimension\n",
    "    max_feature_dim = 0\n",
    "    for client_id in range(1, 5):\n",
    "        try:\n",
    "            coef = np.load(os.path.join(repo_path, f'coef_client_{client_id}.npy'))\n",
    "            max_feature_dim = max(max_feature_dim, len(coef))\n",
    "            print(f\"Client {client_id} feature dimension: {len(coef)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking dimensions for client {client_id}: {e}\")\n",
    "\n",
    "    print(f\"Maximum feature dimension across clients: {max_feature_dim}\")\n",
    "    \n",
    "    if max_feature_dim == 0:\n",
    "        print(\"Error: Could not determine feature dimension from any client\")\n",
    "        return\n",
    "\n",
    "    # ... (keep existing repository setup code)\n",
    "\n",
    "    # Initialize server with modified parameters\n",
    "    server = FederatedServer(num_rounds=10, client_fraction=1.0, learning_rate=0.1)\n",
    "    server.initialize_global_model(max_feature_dim)\n",
    "\n",
    "    # Initialize clients\n",
    "    client_data_sizes = []\n",
    "    for client_id in range(1, 5):\n",
    "        client = FederatedClient(client_id, repo_path, expected_dim=max_feature_dim)\n",
    "        try:\n",
    "            data_size = client.load_data()\n",
    "            client_data_sizes.append(data_size)\n",
    "            server.clients.append(client)\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing client {client_id}: {e}\")\n",
    "\n",
    "    # Federated Learning rounds\n",
    "    best_round_score = float('-inf')\n",
    "    for round_num in range(server.num_rounds):\n",
    "        print(f\"\\nFederated Learning Round {round_num + 1}\")\n",
    "        \n",
    "        selected_clients = server.select_clients()\n",
    "        print(f\"Selected clients: {[i+1 for i in selected_clients]}\")\n",
    "        \n",
    "        client_models = []\n",
    "        selected_weights = []\n",
    "        client_scores = []\n",
    "        \n",
    "        for idx, client_idx in enumerate(selected_clients):\n",
    "            client = server.clients[client_idx]\n",
    "            try:\n",
    "                client_model, val_score = client.train_local_model(server.global_model)\n",
    "                client_models.append(client_model)\n",
    "                selected_weights.append(client_data_sizes[client_idx])\n",
    "                client_scores.append(val_score)\n",
    "                print(f\"Client {client.client_id} completed local training (R² score: {val_score:.3f})\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error training client {client.client_id}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        try:\n",
    "            server.global_model = server.aggregate_models(\n",
    "                client_models, selected_weights, client_scores\n",
    "            )\n",
    "            \n",
    "            # Track best model\n",
    "            round_score = np.mean(client_scores)\n",
    "            if round_score > best_round_score:\n",
    "                best_round_score = round_score\n",
    "                server.best_model = server.global_model.copy()\n",
    "            \n",
    "            print(f\"Round {round_num + 1} aggregation completed (Avg R² score: {round_score:.3f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model aggregation in round {round_num + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save best global model\n",
    "    try:\n",
    "        with open('globalmodel1.pkl', 'wb') as f:\n",
    "            pickle.dump(server.best_model, f)\n",
    "        print(f\"\\nFinal global model saved as globalmodel1.pkl! Best R² score: {best_round_score:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving global model: {e}\")\n",
    "\n",
    "    # Cleanup\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        shutil.rmtree(repo_path)\n",
    "        print(f\"Successfully deleted the repository at {repo_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e20f994-a850-4ab6-ab5d-3928d3148d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists, skipping clone.\n",
      "Client 1 feature dimension: 17\n",
      "Client 2 feature dimension: 17\n",
      "Client 3 feature dimension: 8\n",
      "Client 4 feature dimension: 8\n",
      "Maximum feature dimension across clients: 17\n",
      "\n",
      "Federated Learning Round 1\n",
      "Selected clients: [4, 2, 3, 1]\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Round 1 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 2\n",
      "Selected clients: [4, 3, 2, 1]\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Round 2 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 3\n",
      "Selected clients: [1, 3, 2, 4]\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Round 3 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 4\n",
      "Selected clients: [2, 1, 4, 3]\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Round 4 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 5\n",
      "Selected clients: [3, 1, 4, 2]\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Round 5 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 6\n",
      "Selected clients: [4, 1, 3, 2]\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Round 6 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 7\n",
      "Selected clients: [3, 4, 1, 2]\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Round 7 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 8\n",
      "Selected clients: [4, 3, 1, 2]\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Round 8 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 9\n",
      "Selected clients: [3, 2, 1, 4]\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Round 9 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Federated Learning Round 10\n",
      "Selected clients: [1, 4, 2, 3]\n",
      "Client 1 completed local training (R² score: 0.996)\n",
      "Error in local training for client 4: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 4 completed local training (R² score: -inf)\n",
      "Client 2 completed local training (R² score: 0.997)\n",
      "Error in local training for client 3: operands could not be broadcast together with shapes (8,) (17,) \n",
      "Client 3 completed local training (R² score: -inf)\n",
      "Round 10 aggregation completed (Avg R² score: -inf)\n",
      "\n",
      "Final global model saved as globalmodel1.pkl! Best R² score: -inf\n",
      "Error during cleanup: [WinError 5] Access is denied: 'Farm-params\\\\.git\\\\objects\\\\pack\\\\pack-9793a28fd66f88728bbd621fe2ee08d7dd711de3.idx'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.linear_model import Ridge  # Changed to Ridge regression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "\n",
    "class FederatedServer:\n",
    "    def __init__(self, num_rounds: int = 15, client_fraction: float = 1.0, learning_rate: float = 0.01):\n",
    "        self.global_model = None\n",
    "        self.num_rounds = num_rounds\n",
    "        self.client_fraction = client_fraction\n",
    "        self.clients = []\n",
    "        self.feature_dim = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.best_model = None\n",
    "        self.best_score = float('-inf')\n",
    "        \n",
    "    def initialize_global_model(self, feature_dim: int):\n",
    "        \"\"\"Initialize global model parameters\"\"\"\n",
    "        self.feature_dim = feature_dim\n",
    "        self.global_model = {\n",
    "            'coefficients': np.zeros(feature_dim),\n",
    "            'intercept': 0.0\n",
    "        }\n",
    "        self.best_model = self.global_model.copy()\n",
    "    \n",
    "    def select_clients(self) -> List[int]:\n",
    "        \"\"\"Randomly select a fraction of clients for each round\"\"\"\n",
    "        num_clients = len(self.clients)\n",
    "        num_selected = max(1, int(self.client_fraction * num_clients))\n",
    "        return random.sample(range(num_clients), num_selected)\n",
    "    \n",
    "    def aggregate_models(self, client_models: List[Dict], client_weights: List[float], \n",
    "                        client_scores: List[float]) -> Dict:\n",
    "        \"\"\"Aggregate client models using weighted averaging\"\"\"\n",
    "        if not client_models:\n",
    "            return self.global_model\n",
    "        \n",
    "        # Use simple averaging with equal weights\n",
    "        weighted_coef = np.mean([model['coefficients'] for model in client_models], axis=0)\n",
    "        weighted_intercept = np.mean([model['intercept'] for model in client_models])\n",
    "        \n",
    "        # Gradual update with small learning rate\n",
    "        new_model = {\n",
    "            'coefficients': (1 - self.learning_rate) * self.global_model['coefficients'] + \n",
    "                          self.learning_rate * weighted_coef,\n",
    "            'intercept': (1 - self.learning_rate) * self.global_model['intercept'] + \n",
    "                        self.learning_rate * weighted_intercept\n",
    "        }\n",
    "        \n",
    "        return new_model\n",
    "class FederatedClient:\n",
    "    def __init__(self, client_id: int, data_path: str, expected_dim: int = None):\n",
    "        self.client_id = client_id\n",
    "        self.data_path = data_path\n",
    "        # Use Ridge regression with regularization\n",
    "        self.model = Ridge(alpha=1.0, random_state=42)\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_y = StandardScaler()\n",
    "        self.expected_dim = expected_dim\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        \n",
    "    def load_data(self) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"Load and preprocess client's local data\"\"\"\n",
    "        try:\n",
    "            coef = np.load(os.path.join(self.data_path, f'coef_client_{self.client_id}.npy'))\n",
    "            intercept = np.load(os.path.join(self.data_path, \n",
    "                                           f'intercept_client_{self.client_id}.npy'))\n",
    "            \n",
    "            # Generate synthetic data with more structure\n",
    "            num_samples = 2000  # Increased sample size\n",
    "            np.random.seed(42 + self.client_id)  # Different seed for each client\n",
    "            \n",
    "            # Generate features with some correlation\n",
    "            X = np.random.randn(num_samples, len(coef))\n",
    "            # Add some non-linear features\n",
    "            X = np.column_stack([X, X[:, 0]**2, X[:, 0]*X[:, 1]])\n",
    "            \n",
    "            # Generate target with some noise\n",
    "            noise = np.random.normal(0, 0.1, num_samples)\n",
    "            y = np.dot(X[:, :len(coef)], coef) + intercept + noise\n",
    "            \n",
    "            # Split data\n",
    "            self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "                X[:, :len(coef)], y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Scale features and target\n",
    "            self.X_train = self.scaler_X.fit_transform(self.X_train)\n",
    "            self.X_val = self.scaler_X.transform(self.X_val)\n",
    "            self.y_train = self.scaler_y.fit_transform(self.y_train.reshape(-1, 1)).ravel()\n",
    "            self.y_val = self.scaler_y.transform(self.y_val.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            # Handle dimension mismatch\n",
    "            if self.expected_dim is not None:\n",
    "                if coef.shape[0] < self.expected_dim:\n",
    "                    coef = np.pad(coef, (0, self.expected_dim - coef.shape[0]))\n",
    "                elif coef.shape[0] > self.expected_dim:\n",
    "                    coef = coef[:self.expected_dim]\n",
    "                    \n",
    "            self.coef = coef\n",
    "            self.intercept = intercept\n",
    "            return len(self.X_train)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for client {self.client_id}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def train_local_model(self, global_model: Dict) -> Tuple[Dict, float]:\n",
    "        \"\"\"Train local model using client's data\"\"\"\n",
    "        try:\n",
    "            # Fit model on local data\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            y_pred = self.model.predict(self.X_val)\n",
    "            val_score = r2_score(self.y_val, y_pred)\n",
    "            \n",
    "            # Blend with global model\n",
    "            if global_model is not None:\n",
    "                blend_ratio = 0.7  # Favor local model more\n",
    "                coef = blend_ratio * self.model.coef_ + (1 - blend_ratio) * global_model['coefficients']\n",
    "                intercept = blend_ratio * self.model.intercept_ + (1 - blend_ratio) * global_model['intercept']\n",
    "            else:\n",
    "                coef = self.model.coef_\n",
    "                intercept = self.model.intercept_\n",
    "            \n",
    "            return {\n",
    "                'coefficients': coef,\n",
    "                'intercept': intercept\n",
    "            }, val_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in local training for client {self.client_id}: {e}\")\n",
    "            return global_model, -np.inf\n",
    "            \n",
    "\n",
    "def main():\n",
    "    repo_url = \"https://github.com/555-Satyajit/Farm-params.git\"\n",
    "    local_dir = r\"C:\\Users\\SATYAJIT\\crop yield\\Farm-Params\"\n",
    "    repo_path = \"Farm-params\"\n",
    "\n",
    "    # Clone repository\n",
    "    if not os.path.exists(local_dir):\n",
    "        try:\n",
    "            print(\"Cloning the repository...\")\n",
    "            git.Repo.clone_from(repo_url, local_dir)\n",
    "            print(\"Repository cloned successfully!\")\n",
    "        except git.exc.GitCommandError as e:\n",
    "            print(f\"Error during cloning: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Repository already exists, skipping clone.\")\n",
    "\n",
    "    # First pass: determine maximum feature dimension\n",
    "    max_feature_dim = 0\n",
    "    for client_id in range(1, 5):\n",
    "        try:\n",
    "            coef = np.load(os.path.join(repo_path, f'coef_client_{client_id}.npy'))\n",
    "            max_feature_dim = max(max_feature_dim, len(coef))\n",
    "            print(f\"Client {client_id} feature dimension: {len(coef)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking dimensions for client {client_id}: {e}\")\n",
    "\n",
    "    print(f\"Maximum feature dimension across clients: {max_feature_dim}\")\n",
    "    \n",
    "    if max_feature_dim == 0:\n",
    "        print(\"Error: Could not determine feature dimension from any client\")\n",
    "        return\n",
    "\n",
    "    # ... (keep existing repository setup code)\n",
    "\n",
    "    # Initialize server with modified parameters\n",
    "    server = FederatedServer(num_rounds=10, client_fraction=1.0, learning_rate=0.1)\n",
    "    server.initialize_global_model(max_feature_dim)\n",
    "\n",
    "    # Initialize clients\n",
    "    client_data_sizes = []\n",
    "    for client_id in range(1, 5):\n",
    "        client = FederatedClient(client_id, repo_path, expected_dim=max_feature_dim)\n",
    "        try:\n",
    "            data_size = client.load_data()\n",
    "            client_data_sizes.append(data_size)\n",
    "            server.clients.append(client)\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing client {client_id}: {e}\")\n",
    "\n",
    "    # Federated Learning rounds\n",
    "    best_round_score = float('-inf')\n",
    "    for round_num in range(server.num_rounds):\n",
    "        print(f\"\\nFederated Learning Round {round_num + 1}\")\n",
    "        \n",
    "        selected_clients = server.select_clients()\n",
    "        print(f\"Selected clients: {[i+1 for i in selected_clients]}\")\n",
    "        \n",
    "        client_models = []\n",
    "        selected_weights = []\n",
    "        client_scores = []\n",
    "        \n",
    "        for idx, client_idx in enumerate(selected_clients):\n",
    "            client = server.clients[client_idx]\n",
    "            try:\n",
    "                client_model, val_score = client.train_local_model(server.global_model)\n",
    "                client_models.append(client_model)\n",
    "                selected_weights.append(client_data_sizes[client_idx])\n",
    "                client_scores.append(val_score)\n",
    "                print(f\"Client {client.client_id} completed local training (R² score: {val_score:.3f})\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error training client {client.client_id}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        try:\n",
    "            server.global_model = server.aggregate_models(\n",
    "                client_models, selected_weights, client_scores\n",
    "            )\n",
    "            \n",
    "            # Track best model\n",
    "            round_score = np.mean(client_scores)\n",
    "            if round_score > best_round_score:\n",
    "                best_round_score = round_score\n",
    "                server.best_model = server.global_model.copy()\n",
    "            \n",
    "            print(f\"Round {round_num + 1} aggregation completed (Avg R² score: {round_score:.3f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model aggregation in round {round_num + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save best global model\n",
    "    try:\n",
    "        with open('globalmodel1.pkl', 'wb') as f:\n",
    "            pickle.dump(server.best_model, f)\n",
    "        print(f\"\\nFinal global model saved as globalmodel1.pkl! Best R² score: {best_round_score:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving global model: {e}\")\n",
    "\n",
    "    # Cleanup\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        shutil.rmtree(repo_path)\n",
    "        print(f\"Successfully deleted the repository at {repo_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f99efaa-5f24-40f4-9a7f-af30373de9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
